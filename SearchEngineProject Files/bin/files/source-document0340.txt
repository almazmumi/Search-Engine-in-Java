 The INTERNIST example also demonstrates that there is significant and unavoidable ontological commitment even at the level of the familiar representation technologies. Logic, rules, frames, etc., each embody a viewpoint on the kinds of things that are important in the world. Logic, for instance, involves a commitment to viewing the world in terms of individual entities and relations between them. Rule-based systems view the world in terms of attribute-object-value triples and the rules of plausible inference that connect them, while frames have us thinking in terms of prototypical objects. Each of these thus supplies its own view of what is important to attend to, and each suggests, conversely, that anything not easily seen in those terms may be ignored. This is of course not guaranteed to be correct, since anything ignored may later prove to be relevant. But the task is hopeless in principle—every representation ignores something about the world—hence the best we can do is start with a good guess. The existing representation technologies supply one set of guesses about what to attend to and what to ignore. Selecting any of them thus involves a degree of ontological commitment: the selection will have a significant impact on our perception of and approach to the task, and on our perception of the world being modeled. Commitments accumulate in layers[edit] The ontologic commitment of a representation thus begins at the level of the representation technologies and accumulates from there. Additional layers of commitment are made as the technology is put to work. The use of frame-like structures in INTERNIST offers an illustrative example. At theThe novelist Nicholas Delanco taught himself to read at age six during a transatlantic crossing by studying a book about boats. Brain activity in young and older children can be used to predict future reading skill.  most fundamental level, the decision to view diagnosis in terms of frames suggests thinking in terms of prototypes, defaults, and a taxonomic hierarchy. But prototypes of what, and how shall the taxonomy be organized? An early description of the system [23] shows how these questions were answered in the task at hand, supplying the second layer of commitment: The knowledge base underlying the INTERNIST system is composed of two basic types of elements: disease entities and manifestations.... [It] also contains a...hierarchy of disease categories, organized primarily around the concept of organ systems, having at the top level such categories as "liver disease," "kidney disease," etc. The prototypes are thus intended to capture prototypical diseases (e.g., a "classic case" of a disease), and they will be organized in a taxonomy indexed around organ systems. This is a sensible and intuitive set of choices but clearly not the only way to apply frames to the task; hence it is another layer of ontological commitment. At the third (and in this case final) layer, this set of choices is instantiated: which diseases will be included and in which branches of the hierarchy will they appear? Ontologic questions that arise even at this level can be quite fundamental. Consider for example determining which of the following are to be considered diseases (i.e., abnormal states requiring cure): alcoholism, back pain, and chronic fatigue syndrome. The ontologic commitment here is sufficiently obvious and sufficiently important that it is often a subject of debate in the field itself, quite independent of building automated reasoners. Similar sorts of decisions have to be made with all the representation technologies, because each of them supplies only a first order guess about how to see the world: they offer a way of seeing but don't indicate how to instantiate that view. As frames suggest prototypes and taxonomies but do not tell us which things to select as prototypes, rules suggest thinking in terms of plausible inferences, but don't tell us which plausible inferences to attend to. Similarly logic tells us to view the world in terms of individuals and relations, but does not specify which individuals and relations to use. Commitment to a particular view of the world thus starts with the choice of a representation technology, and accumulates as subsequent choices are made about how to see the world in those terms. Valuation-based system (VBS) is a framework for knowledge representation and inference. Real-world problems are modeled in this framework by a network of interrelated entities, called variables. The relationships between variables (possibly uncertain or imprecise) are represented by the functions called valuations. The two basic operations for performing inference in a VBS are combination and marginalization. Combination corresponds to the aggregation of knowledge, while marginalization refers to the focusing (coarsening) of it. VBSs were introduced by Prakash P. Shenoy in 1989 as general frameworks for managing uncertainty in expert systems. Applications[edit] VBS are used for knowledge representation in expert systems and data fusion. Bibliography[edit] Shenoy, Prakash P. A valuation-based language for expert systems. Int. Journal of Approximate Reasoning, vol. 3, no. 2, pages 383-411, 1989. Shenoy, Prakash P. Valuation based systems: A framework for managing uncertainty in expert systems. In L. A. Zadeh and J. Kacprzyk, editors, Fuzzy Logic and the Management of Uncertainty, chapter 4, pages 83–104. Wiley, New York, 1992. Shenoy, Prakash P. and Shafer, G. Axioms for probability and belief-function propagation. In J. Pearl G. Shafer, editor, Readings in uncertain reasoning, pages 575-610. San Mateo, CA: Morgan Kaufmann, 1990. 